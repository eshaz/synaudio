<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=1300" />
    <title>SynAudio Demo</title>
    <meta
      name="description"
      content="SynAudio - JavaScript library that finds the synchronization point between two similar audio clips"
    />
    <meta name="theme-color" content="#000000" />
    <meta name="title" content="SynAudio Demo" />
    <script src="synaudio.min.js"></script>
  </head>
  <style>
    html,
    body {
      text-size-adjust: none;
    }
    body {
      background: linear-gradient(
            217deg,
            rgba(255, 0, 0, 0.3),
            rgba(255, 0, 0, 0) 70.71%
          )
          fixed,
        linear-gradient(127deg, rgba(0, 255, 0, 0.3), rgba(0, 255, 0, 0) 70.71%)
          fixed,
        linear-gradient(336deg, rgba(0, 0, 255, 0.3), rgba(0, 0, 255, 0) 70.71%)
          fixed;
      font-family: monospace;
      margin: 0 2%;
    }
    header {
      text-align: center;
    }
    .header-links {
      font-size: 16px;
      font-family: sans-serif;
      text-decoration: none;
      user-select: none;
    }
    .header-link {
      text-decoration: none;
    }
    strong {
      font-family: sans-serif;
    }
    input,
    label,
    button,
    select {
      margin: 5px;
    }
    pre {
      margin: 0px;
    }
    label {
      user-select: none;
    }
    button {
      user-select: none;
    }
    hr {
      margin: 20px 0;
    }
    .column {
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
    }
    .row {
      display: flex;
      flex-direction: row;
    }
    .center {
      align-items: center;
      justify-content: center;
    }
    .start {
      align-items: flex-start;
    }
    .grow {
      display: flex;
      flex: 1;
    }
    .popover-wrapper {
      position: relative;
    }
    .popover-content {
      opacity: 0;
      visibility: hidden;
      position: absolute;
      color: rgb(0, 0, 0);
      background-color: #cacaca;
      padding: 1.5rem;
      width: auto;
      border-width: 2px;
      border-color: #000;
      border-style: solid;
      border-radius: 10px;
      transition: all 0.25s cubic-bezier(0.75, -0.02, 0.2, 0.97);
    }
    .popover-wrapper:hover .popover-content {
      z-index: 10;
      opacity: 1;
      visibility: visible;
      transition: all 0.25s cubic-bezier(0.75, -0.02, 0.2, 0.97);
    }
  </style>
  <script>
    let audioFormData, optionsFormData;

    // prettier-ignore
    const audioClips = {
      ["Flight of the Bumblebee"]: {
        ["Full Audio (MP3 128kb/s)"]: "clips/bumblebee/mpeg.cbr.mp3",
        ["Clip @ 194648 Samples (MP3 128kb/s)"]: "clips/bumblebee/mpeg.cbr.194648.mp3",
        ["Clip @ 194648 Samples (MP3 64kb/s)"]: "clips/bumblebee/mpeg.64.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s)"]: "clips/bumblebee/mpeg.32.194648.mp3",
        ["Clip @ 287549 Samples (MP3 128kb/s)"]: "clips/bumblebee/mpeg.cbr.287549.mp3",
        ["Clip @ 312782 Samples (MP3 32kb/s)"]: "clips/bumblebee/mpeg.32.312782.mp3",
        ["Clip @ 1601425 Samples (MP3 128kb/s)"]: "clips/bumblebee/mpeg.cbr.1601425.mp3",
        ["Clip @ 2450800 Samples (MP3 128kb/s)"]: "clips/bumblebee/mpeg.cbr.2450800.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen2)"]: "clips/bumblebee/mpeg.32.gen2.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen3)"]: "clips/bumblebee/mpeg.32.gen3.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen4)"]: "clips/bumblebee/mpeg.32.gen4.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen5)"]: "clips/bumblebee/mpeg.32.gen5.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen6)"]: "clips/bumblebee/mpeg.32.gen6.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen7)"]: "clips/bumblebee/mpeg.32.gen7.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen8)"]: "clips/bumblebee/mpeg.32.gen8.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen9)"]: "clips/bumblebee/mpeg.32.gen9.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen10)"]: "clips/bumblebee/mpeg.32.gen10.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen11)"]: "clips/bumblebee/mpeg.32.gen11.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen12)"]: "clips/bumblebee/mpeg.32.gen12.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen13)"]: "clips/bumblebee/mpeg.32.gen13.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen14)"]: "clips/bumblebee/mpeg.32.gen14.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen15)"]: "clips/bumblebee/mpeg.32.gen15.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen16)"]: "clips/bumblebee/mpeg.32.gen16.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen17)"]: "clips/bumblebee/mpeg.32.gen17.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen18)"]: "clips/bumblebee/mpeg.32.gen18.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen19)"]: "clips/bumblebee/mpeg.32.gen19.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen20)"]: "clips/bumblebee/mpeg.32.gen20.194648.mp3",
      }
    }

    const setSelectOptions = (el) => {
      let html = "";
      for (const [optgroup, options] of Object.entries(audioClips)) {
        html += `<optgroup label="${optgroup}">`;

        for (const [name, value] of Object.entries(options))
          html += `<option value="${value}">${name}</option>`;

        html += "</optgroup>";
      }
      el.innerHTML += html;
    };

    const handleFileOrSelect = (file, select) => {
      select.addEventListener("change", (e) => {
        if (e.target.value) file.value = "";
      });
      file.addEventListener("change", (e) => {
        if (e.target.value) select.value = "";
      });
    };

    const mapSelectedOptions = (e) =>
      [...e.selectedOptions].map((o) => o.value).filter((s) => s !== "");
    const mapSelectedFiles = (e) => [...e.files];

    const mapClipInput = (select, file, prevSelect, prevFile) => {
      const selectedOptions = mapSelectedOptions(select);
      const selectedFiles = mapSelectedFiles(file);

      return selectedOptions.length ? selectedOptions : selectedFiles;
    };
  </script>
  <body>
    <header>
      <h1 style="margin-bottom: 0px">
        <a href="https://github.com/eshaz/synaudio"><b>synaudio</b></a>
      </h1>
      <h4>
        JavaScript library that finds the synchronization point between two
        similar audio clips.
      </h4>
    </header>
    <hr />
    <p>
      The
      <a href="https://github.com/eshaz/wasm-audio-decoders">synaudio</a>
      library synchronizes two similar audio clips using the
      <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient"
        >Pearson Correlation Coefficient</a
      >.
    </p>
    <p>
      This is implemented using Web Assembly SIMD instructions to used
      significantly increase performance. A single and multi-threaded Web Worker
      implementation is available as well that further increases performance.
    </p>
    <p>
      This library is used in
      <a href="https://eshaz.github.io/icecast-metadata-js"
        >icecast-metadata-player</a
      >
      to synchronize Icecast streaming audio between different connections and
      audio codecs.
    </p>
    <hr />
    <h3>How to use the demo</h3>
    <h4>Sync Two Clips</h4>
    <ul>
      <li>Select two audio clips (one base clip, and one comparison clip).</li>
      <li>
        Click <b>Find Correlation</b> to find the sample offset within the base
        audio where the comparison audio matches with the best correlation.
      </li>
      <li>
        Play the result audio, which is the comparison audio spliced into the
        base audio at the sample offset, to sonically verify the correlation
        result.
        <ul>
          <li>
            When the <i>correlation coefficient</i> is high (over 50%) the match
            will likely align with sample accurate results.
          </li>
          <li>
            When the <i>correlation coefficient</i> is low (under 50%) there is
            likely not a match between the base and comparison audio clips.
          </li>
        </ul>
      </li>
    </ul>
    <h4>Sync Multiple Clips</h4>
    <ul>
      <li>Select two or more audio clips.</li>
      <li>
        Click <b>Find Correlation</b> to find the best match between all the
        clips.
      </li>
      <li>
        Play the resulting audio clips(s), which represents the best match(es)
        between all the clips, to sonically verify the correlation results.
        <ul>
          <li>
            Hover over the <i>Results</i> area to see the list of matches.
          </li>
          <li>
            Each match within <i>Results</i> is a nested array representing a
            chain of matching audio clips.
          </li>
        </ul>
      </li>
    </ul>
    <hr />
    <div class="row">
      <form
        name="audioForm"
        id="audioForm"
        onsubmit="return false;"
        class="row"
        style="flex-grow: 1"
      >
        <fieldset style="flex-grow: 1">
          <legend>Select Audio Clips</legend>
          <ol>
            <li style="margin-bottom: 5px">
              <input
                type="radio"
                id="two-clips-mode"
                name="correlationMode"
                value="two-clips-mode"
                checked
              />
              <label for="two-clips-mode">Two Clips</label>
              <input
                type="radio"
                id="multiple-clips-mode"
                name="correlationMode"
                value="multiple-clips-mode"
              />
              <label for="multiple-clips-mode">Multiple Clips</label>
            </li>
            <div id="two-clips-fieldset" class="column start">
              <li>
                <div id="base-audio-container">
                  <select id="base-audio-select" name="baseAudioSelect">
                    <option value="" disabled selected>
                      Select a base audio clip
                    </option>
                  </select>
                  <span>or</span>
                  <input
                    type="file"
                    id="base-audio-file"
                    name="baseAudioFile"
                    accept=".mp3, .mp2, .mp1, .mpg, .ogg, .opus"
                  />
                </div>
              </li>
              <li>
                <div id="comparison-audio-container">
                  <select
                    id="comparison-audio-select"
                    name="comparisonAudioSelect"
                  >
                    <option value="" disabled selected>
                      Select a comparison audio clip
                    </option>
                  </select>
                  <span>or</span>
                  <input
                    type="file"
                    id="comparison-audio-file"
                    name="comparisonAudioFile"
                    accept=".mp3, .mp2, .mp1, .mpg, .ogg, .opus"
                  />
                </div>
              </li>
            </div>
            <div
              name="multiple-clips-fieldset"
              id="multiple-clips-fieldset"
              style="display: none"
            >
              <li>
                <div id="multiple-audio-container">
                  <select
                    id="multiple-audio-select"
                    name="multipleAudioSelect"
                    multiple
                    style="height: 200px; width: 95%"
                  >
                    <option value="" disabled selected>
                      Select Two or More Audio Clips
                    </option>
                  </select>
                  <div style="margin-left: 5px">
                    <span>or</span>
                    <input
                      type="file"
                      id="multiple-audio-file"
                      name="multipleAudioFile"
                      accept=".mp3, .mp2, .mp1, .mpg, .ogg, .opus"
                      multiple
                    />
                  </div>
                </div>
              </li>
            </div>
            <li>
              <button id="find-correlation" disabled>Find Correlation</button>
            </li>
          </ol>
        </fieldset>
        <fieldset id="synaudio-results" class="row" style="flex-grow: 1">
          <legend>SynAudio Results</legend>
          <table style="font-weight: bold; border-spacing: 10px 0; width: 100%">
            <tr id="correlation-coefficient-row">
              <td>Correlation Coefficient</td>
              <td style="color: darkred" id="correlation-coefficient">-</td>
            </tr>
            <tr id="correlation-sample-offset-row">
              <td>Sample Offset</td>
              <td style="color: darkred" id="correlation-sample-offset">-</td>
            </tr>
            <tr id="correlation-results-json-row" style="display: none">
              <td class="popover-wrapper" style="padding-bottom: 65%">
                <i>Hover to see results</i>
                <div id="correlation-results-json"></div>
              </td>
              <td></td>
            </tr>
            <tr>
              <td>Time spent</td>
              <td style="color: darkred" id="correlation-time-spent">-</td>
            </tr>
            <tr>
              <td>Rate (1x is realtime)</td>
              <td style="color: darkred" id="correlation-rate">-</td>
            </tr>
            <tr>
              <td>Bytes per second</td>
              <td style="color: darkred" id="correlation-bytes-per-sec">-</td>
            </tr>
          </table>
        </fieldset>
      </form>
      <form
        name="optionsForm"
        id="optionsForm"
        onsubmit="return false;"
        class="row"
        style="flex-grow: 1"
      >
        <fieldset id="synaudio-options" class="column" style="flex-grow: 1">
          <legend>SynAudio Options</legend>
          <table>
            <tr
              title="Selects the method on the SynAudio instance to execute.
* sync: Executes on the main thread.
* syncWorker: Executes in a Web Worker.
* syncWorkerConcurrent: Executes in multiple Web Workers (multi-threaded).
          "
              id="correlation-method-row"
            >
              <td>
                <label for="correlation-method">Correlation Method</label>
              </td>
              <td>
                <select id="correlation-method" name="correlationMethod">
                  <option value="sync">sync</option>
                  <option value="syncWorker">syncWorker</option>
                  <option selected value="syncWorkerConcurrent">
                    syncWorkerConcurrent
                  </option>
                </select>
              </td>
            </tr>
            <tr
              title="Selects number of threads to spawn when running concurrent operations"
              id="correlation-threads-row"
            >
              <td>
                <label for="correlation-threads">Correlation Threads</label>
              </td>
              <td>
                <input
                  id="correlation-threads"
                  name="correlationThreads"
                  type="number"
                  min="1"
                  value="1"
                />
              </td>
            </tr>
            <tr
              title="Selects the sample size in audio samples to compare when determining the best correlation.
* This value can be increased for better accuracy, at the expense of execution time."
            >
              <td>
                <label for="correlation-sample-size"
                  >Correlation Sample Size</label
                >
              </td>
              <td>
                <input
                  id="correlation-sample-size"
                  name="correlationSampleSize"
                  type="number"
                  value="11025"
                />
              </td>
            </tr>
            <tr
              title="Selects the number of samples that are skipped during each iteration while searching for the best correlation.
* This value can be decreased for better accuracy, at the expense of execution time."
            >
              <td>
                <label for="initial-granularity">Initial Granularity</label>
              </td>
              <td>
                <input
                  id="initial-granularity"
                  name="initialGranularity"
                  type="number"
                  value="16"
                />
              </td>
            </tr>
            <tr
              title="Threshold that will filter out any low correlation matches.
* Only applicable to Multiple Clips (`syncMultiple`)"
              id="correlation-threshold-row"
              style="display: none"
            >
              <td>
                <label for="correlation-threshold">Correlation Threshold</label>
              </td>
              <td>
                <input
                  id="correlation-threshold"
                  name="correlationThreshold"
                  type="number"
                  value="0.5"
                  min="0"
                  max="1"
                />
              </td>
            </tr>
          </table>
        </fieldset>
        <fieldset id="fft-options" class="column" style="flex-grow: 1">
          <legend>FFT Options</legend>
          <table>
            <tr>
              <td>
                <label for="fft-bins">Bin Size (height)</label>
              </td>
              <td>
                <select name="fftBins" id="fft-bins">
                  <option selected value="auto">auto</option>
                </select>
              </td>
            </tr>
            <tr>
              <td>
                <label for="fft-interval">Interval Size (width)</label>
              </td>
              <td>
                <select name="fftInterval" id="fft-interval">
                  <option selected value="auto">auto</option>
                </select>
              </td>
            </tr>
            <tr>
              <td>
                <label for="fft-scale">Scale</label>
              </td>
              <td>
                <select name="fftScale" id="fft-scale">
                  <option selected value="log">logarithmic</option>
                  <option value="lin">linear</option>
                </select>
              </td>
            </tr>
          </table>
        </fieldset>
      </form>
    </div>
    <div id="result-fft-container"></div>
    <div id="fft-container"></div>
  </body>
  <script>
    ("use strict");
    const baseAudioClipKey = "base";
    const comparisonAudioClipKey = "comparison";
    const correlationAudioClipKey = "correlation";

    const AudioContext = window.AudioContext || window.webkitAudioContext;
    let audioCtx;

    // statically initialize audio context and start using a DOM event
    if (AudioContext) {
      const audioCtxErrorHandler = (e) => {
        console.error(
          "Failed to start the AudioContext. WebAudio playback will not be possible.",
          e
        );
      };

      // hack for iOS Audio element controls support
      // iOS will only enable AudioContext.resume() when called directly from a UI event
      // https://stackoverflow.com/questions/57510426
      const events = ["touchstart", "touchend", "mousedown", "keydown"];

      const unlock = () => {
        events.forEach((e) => document.removeEventListener(e, unlock));

        audioCtx = new AudioContext({
          latencyHint: "interactive",
        });

        audioCtx
          .resume()
          .then(() => {
            // hack for iOS to continue playing while locked
            audioCtx.onstatechange = () => {
              if (audioCtx.state !== "running")
                audioCtx.resume().catch(audioCtxErrorHandler);
            };
          })
          .catch(audioCtxErrorHandler);

        audioCtx.destination.channelCount =
          audioCtx.destination.maxChannelCount;
      };

      events.forEach((e) => document.addEventListener(e, unlock));
    }

    const PROGRESS_FACTOR = 100;

    const PLAY = "▶";
    const STOP = "■";

    const fftPlaceholders = {
      addAClip: "<i>Select two or more audio clips.</i>",
      [baseAudioClipKey]: "<i>Select a base audio clip.</i>",
      [comparisonAudioClipKey]: "<i>Select a comparison audio clip.</i>",
      [correlationAudioClipKey]:
        "<i>Select audio clips and click <b>Find Correlation</b>.</i>",
    };

    class WebAudioPlayer {
      constructor(audioBuffer) {
        this.audioBuffer = audioBuffer;

        this.buildPlayer();

        this.startProgress = () => {
          clearInterval(this.progressInterval);
          this.progressInterval = setInterval(() => {
            if (this.action === STOP) {
              const currentTime =
                this.offset +
                (audioCtx.currentTime * PROGRESS_FACTOR - this.start);
              this._progressBarEl.value = currentTime;
              this._timeEl.innerHTML = this.getTime(
                currentTime / PROGRESS_FACTOR
              );
            }
          }, 2);
        };
        this.stopProgress = () => {
          clearInterval(this.progressInterval);
        };
      }

      buildPlayer() {
        this._playerEl = document.createElement("div");

        this._progressBarEl = document.createElement("input");
        this._progressBarEl.value = 0;
        this._progressBarEl.type = "range";
        this._progressBarEl.style = "width: 100%; margin: 0; padding: 0;";
        this._progressBarEl.oninput = () => this.seek();

        this._playbackEl = document.createElement("button");
        this._playbackEl.style =
          "display: flex; justify-content: center; width: 25px;";
        this._playbackEl.onclick = () => this.playPause();
        this._playbackEl.innerHTML = PLAY;

        this._timeEl = document.createElement("div");
        this._timeEl.style =
          "display: flex; align-items: center; padding-left: 5px;";
        this._timeEl.innerHTML = "00:00.000";

        const playerControlsEl = document.createElement("div");
        playerControlsEl.style =
          "display: flex; flex-direction: row; align-items: center;";

        this._playerEl.appendChild(this._progressBarEl);
        this._playerEl.appendChild(playerControlsEl);
        playerControlsEl.appendChild(this._playbackEl);
        playerControlsEl.appendChild(this._timeEl);
      }

      get action() {
        return this._playbackEl.innerHTML;
      }

      get playerEl() {
        return this._playerEl;
      }

      get length() {
        return this.audioBuffer.length;
      }

      getTime(seconds) {
        return new Date(seconds * 1000).toISOString().substr(14, 9);
      }

      seek() {
        this.stop();
        this.play(parseFloat(this._progressBarEl.value));
      }

      play(offset = 0) {
        // start playing audio
        audioCtx.resume();
        this.source = audioCtx.createBufferSource();
        this.source.buffer = this.audioBuffer;
        this.source.connect(audioCtx.destination);
        this.source.start(0, offset / PROGRESS_FACTOR);
        this.source.onended = () => {
          this.stop();
        };

        // setup progress bar
        this.start = audioCtx.currentTime * PROGRESS_FACTOR;
        this.offset = offset;
        this._progressBarEl.min = 0;
        this._progressBarEl.max = this.audioBuffer.duration * PROGRESS_FACTOR;
        this._progressBarEl.value = offset;

        // start progress bar and add event listeners
        this._progressBarEl.addEventListener("pointerup", this.startProgress);
        this._progressBarEl.addEventListener("pointerdown", this.stopProgress);
        this.startProgress();

        // update file status and play button
        this._playbackEl.innerHTML = STOP;
      }

      stop() {
        // stop playing audio
        if (this.source) {
          this.source.onended = null;
          this.source.stop();
          this.source.disconnect();
        }

        // stop progress bar and clear event listeners
        this._progressBarEl.removeEventListener(
          "pointerup",
          this.startProgress
        );
        this._progressBarEl.removeEventListener(
          "pointerdown",
          this.stopProgress
        );
        this.stopProgress();

        // update file status and play button
        this._playbackEl.innerHTML = PLAY;
      }

      playPause() {
        if (this.action === PLAY) {
          this.play();
        } else {
          this.stop();
        }
      }
    }

    class FFTCanvas {
      static FFT_BIN_OPTIONS = [
        32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768,
      ];

      static FFT_INTERVAL_OPTIONS = [256, 512, 1024, 2048, 4096, 8192, 16384];

      constructor(audioKey) {
        this._audioKey = audioKey;
        this._translatedSamples = 0;

        this._sampleRate = audioCtx.sampleRate;
        this._audioBuffers = [];
        this._audioBufferData = new WeakMap();

        this._heightDivision = 6;

        this._newCanvasWorker();
      }

      async addAudioBuffer(data, audioBufferData = {}) {
        let decoded = data;

        if (!(data instanceof AudioBuffer))
          decoded = await audioCtx.decodeAudioData(data);

        this._audioBuffers.push(decoded);
        this._audioBufferData.set(decoded, {
          color: audioBufferData.color, // rgb
          offset: audioBufferData.offset || 0,
          fft: audioBufferData.fft || {},
        });

        // need to overlap the audio buffer based on offset
        this._newPlayer(this.concatAudioBuffers());
      }

      concatAudioBuffers() {
        return this._audioBuffers
          .map((buffer) => ({
            buffer,
            ...this._audioBufferData.get(buffer),
          }))
          .sort((a, b) => a.offset - b.offset)
          .reduce((finalBuffer, buffer) => {
            for (let i = 0; i < this.channelCount; i++) {
              finalBuffer.copyToChannel(
                buffer.buffer.getChannelData(i),
                i,
                buffer.offset
              );
            }
            return finalBuffer;
          }, audioCtx.createBuffer(this.channelCount, this.length, this.sampleRate));
      }

      get audioBuffers() {
        return this._audioBuffers;
      }

      getAudioBufferData(audioBuffer) {
        return this._audioBufferData.get(audioBuffer);
      }

      destroy() {
        this._webAudioPlayer.stop();
        this._terminateCanvas();
        this._canvasContainer.innerHTML =
          fftPlaceholders[this._audioKey] || fftPlaceholders.addAClip;
      }

      get channelCount() {
        return this.audioBuffers.reduce(
          (acc, audioBuffer) =>
            acc > audioBuffer.numberOfChannels
              ? acc
              : audioBuffer.numberOfChannels,
          0
        );
      }

      get sampleRate() {
        return audioCtx.sampleRate;
      }

      get length() {
        return this.audioBuffers.reduce((acc, audioBuffer) => {
          const totalLength =
            this._audioBufferData.get(audioBuffer).offset + audioBuffer.length;

          return acc > totalLength ? acc : totalLength;
        }, 0);
      }

      get displayLength() {
        return this._displayLength;
      }

      set displayLength(length) {
        const oldDisplayLength = this._displayLength;

        this._displayLength = length || this.length;

        if (oldDisplayLength !== this._displayLength) {
          this.drawFFT();
        }
      }

      get height() {
        return this.fftBins / 2;
      }

      get width() {
        return window.innerWidth * 0.94; //document.getElementsByTagName("body")[0].clientWidth;
      }

      get fftInterval() {
        const maxWidth = this.width;
        const fftInterval = document.getElementById("fft-interval").value;

        return fftInterval === "auto"
          ? FFTCanvas.FFT_INTERVAL_OPTIONS.reduceRight((acc, val) =>
              maxWidth > this._displayLength / val ? val : acc
            )
          : parseInt(fftInterval);
      }

      get fftBins() {
        const maxHeight = window.innerHeight / this._heightDivision;
        const fftBins = document.getElementById("fft-bins").value;

        return fftBins === "auto"
          ? FFTCanvas.FFT_BIN_OPTIONS.reduceRight((acc, val) =>
              maxHeight < val ? val : acc
            )
          : parseInt(fftBins);
      }

      get fftScale() {
        return document.getElementById("fft-scale").value;
      }

      _sampleToPixel(sample) {
        const fftInterval = this.fftInterval;
        const widthScale = this.width / (this.displayLength / fftInterval);

        return Math.round((sample / fftInterval) * widthScale) || 0;
      }

      _newPlayer(audioBuffer) {
        if (this._webAudioPlayer) this._webAudioPlayer.stop();

        this._webAudioPlayer = new WebAudioPlayer(audioBuffer);
        this._playerEl = this._webAudioPlayer._playerEl;
      }

      _newCanvasWorker() {
        const source = () => {
          let fftXCursor,
            fftYCursor,
            widthScale,
            displayLength,
            canvas,
            canvasCtx,
            patternCanvas,
            patternCanvasCtx,
            logTables,
            sampleRate,
            fftScale,
            fftInterval,
            fftBins;

          const fill = (fillStyle, x, y, width, height) => {
            canvasCtx.fillStyle = fillStyle;
            canvasCtx.fillRect(x, y, width, height);
          };

          const fillPattern = (x, y, width, height) => {
            fill(
              canvasCtx.createPattern(patternCanvas, "repeat"),
              x,
              y,
              width,
              height
            );
          };

          self.onmessage = async ({ data: { name, payload, messageId } }) => {
            switch (name) {
              case "init":
                // precalculate logarithmic rectangle heights
                logTables = {};
                sampleRate = payload.sampleRate;
                const sampleRateLog = Math.log10(sampleRate / 2);

                for (let binOption of payload.fftBinOptions) {
                  binOption /= 2;

                  logTables[binOption] = [];

                  const logGap =
                    binOption /
                    ((Math.log10(binOption - 1) * (binOption - 1)) /
                      sampleRateLog);

                  for (let i = 0; i < binOption; i++)
                    logTables[binOption].push(
                      Math.round(
                        ((Math.log10(i) * (binOption - 1)) / sampleRateLog) *
                          logGap
                      )
                    );
                }

                patternCanvas = payload.patternCanvas;
                patternCanvasCtx = patternCanvas.getContext("2d", {
                  alpha: false,
                });

                patternCanvas.width = 8;
                patternCanvas.height = 8;
                patternCanvasCtx.fillStyle = "#333";
                patternCanvasCtx.fillRect(
                  0,
                  0,
                  patternCanvas.width,
                  patternCanvas.height
                );
                /*patternCanvasCtx.beginPath();
                patternCanvasCtx.moveTo(0, 0);
                patternCanvasCtx.lineTo(8, 8);
                patternCanvasCtx.moveTo(0, 8);
                patternCanvasCtx.lineTo(8, 0);
                patternCanvasCtx.lineWidth = 1;
                patternCanvasCtx.stroke();*/
                break;
              case "canvas":
                fftXCursor = 0;
                fftYCursor = 0;

                canvas = payload.canvas;
                canvasCtx = canvas.getContext("2d", { alpha: false });
                break;
              case "options":
                fftScale = payload.fftScale;
                fftInterval = payload.fftInterval;
                fftBins = payload.fftBins;
                displayLength = payload.displayLength;

                widthScale = canvas.width / (displayLength / fftInterval);
                break;
              case "fill":
                fill(payload, 0, 0, canvas.width, canvas.height);
                break;
              case "fillPattern":
                fillPattern(0, 0, canvas.width, canvas.height);
                break;
              case "draw":
                if (payload.mode === "full") fftXCursor = 0;

                for (const bins of payload.fft) {
                  fftYCursor = 0;

                  let fftYPrevious;

                  for (let binIdx = 0; binIdx < bins.length; binIdx++) {
                    const r = Math.round(
                      (payload.color[0] * bins[binIdx]) / 255
                    );
                    const g = Math.round(
                      (payload.color[1] * bins[binIdx]) / 255
                    );
                    const b = Math.round(
                      (payload.color[2] * bins[binIdx]) / 255
                    );

                    canvasCtx.fillStyle = `rgb(${r},${g},${b})`;

                    fftYPrevious = fftYCursor;
                    fftYCursor =
                      fftScale === "log"
                        ? logTables[bins.length][binIdx]
                        : binIdx;

                    canvasCtx.fillRect(
                      (payload.offset / fftInterval + fftXCursor) * widthScale,
                      bins.length - fftYCursor,
                      widthScale + widthScale / 2,
                      fftYCursor - fftYPrevious
                    );
                  }

                  fftXCursor++;
                }

                if (payload.mode === "last-partial") fftXCursor = 0;
                break;
              case "translateXSamples":
                const image = canvasCtx.getImageData(
                  0,
                  0,
                  canvas.width,
                  canvas.height
                );

                fillPattern(0, 0, canvas.width, canvas.height);
                canvasCtx.putImageData(
                  image,
                  (payload / fftInterval) * widthScale,
                  0
                );
                break;
            }

            requestAnimationFrame(() => self.postMessage(messageId));
          };
        };

        if (this._canvasWorker) {
          this._terminateCanvas();
        }

        this._canvasWorker = new Worker(
          URL.createObjectURL(
            new Blob([`"use strict";(${source.toString()})()`], {
              type: "text/javascript",
            })
          )
        );

        this._messageId = Number.MIN_SAFE_INTEGER;
        this._pendingMessages = new Map();

        this._canvasWorker.onmessage = ({ data: messageId }) => {
          const messagePromise = this._pendingMessages.get(messageId);

          if (messagePromise) {
            messagePromise();
            this._pendingMessages.delete(messageId);
          }
        };

        const offscreenPatternCanvas = document
          .createElement("canvas")
          .transferControlToOffscreen();

        this._postToWorker(
          "init",
          {
            sampleRate: this._sampleRate,
            fftBinOptions: FFTCanvas.FFT_BIN_OPTIONS,
            patternCanvas: offscreenPatternCanvas,
          },
          [offscreenPatternCanvas]
        );
      }

      async _postToWorker(name, payload, transferList) {
        const messageId = this._messageId++;

        return new Promise((resolve, reject) => {
          this._pendingMessages.set(messageId, resolve);
          this._canvasWorker.postMessage(
            { name, payload, messageId },
            transferList
          );
        });
      }

      async _newCanvas() {
        this._canvas = document.createElement("canvas");
        this._canvas.id = this._audioKey + "-fft-canvas";
        this._canvas.width = this.width;
        this._canvas.height = this.height;
        const offscreenCanvas = this._canvas.transferControlToOffscreen();

        this._canvasContainer = document.getElementById(
          this._audioKey + "-fft"
        );

        this._playerEl.style.width =
          this._sampleToPixel(this._webAudioPlayer.length) + "px";

        this._playerEl.style.marginLeft =
          this._sampleToPixel(this._translatedSamples) + "px";

        this._canvasContainer.innerHTML = "";
        this._canvasContainer.appendChild(this._canvas);
        this._canvasContainer.appendChild(this._playerEl);

        await this._postToWorker("canvas", { canvas: offscreenCanvas }, [
          offscreenCanvas,
        ]);
      }

      async _fillCanvas(fillStyle) {
        await this._postToWorker("fill", fillStyle);
      }

      async _fillPatternCanvas(fillStyle) {
        await this._postToWorker("fillPattern");
      }

      async _drawCanvas(mode, fft, color, offset) {
        await this._postToWorker("draw", { mode, fft, color, offset });
      }

      async _terminateCanvas() {
        // clear out the canvas
        await this._fillCanvas("rgb(255, 255, 255)");
        this._canvasWorker.terminate();
        this._canvasWorker = null;
      }

      async translateXSamples(samples) {
        this._translatedSamples = samples;
        this._playerEl.style.marginLeft =
          this._sampleToPixel(this._translatedSamples) + "px";

        const audioData = this._audioBufferData.get(this._audioBuffers[0]);

        await this._postToWorker(
          "translateXSamples",
          this._translatedSamples - audioData.offset
        );

        audioData.offset = this._translatedSamples;
      }

      async drawFFT() {
        const fftBins = this.fftBins;
        const fftInterval = this.fftInterval;

        if (
          this._canvas?.width !== this.width ||
          this._canvas?.height !== this.height
        )
          await this._newCanvas();

        await this._postToWorker("options", {
          displayLength: this.displayLength,
          fftScale: this.fftScale,
          fftInterval,
          fftBins,
        });

        await this._fillPatternCanvas();

        for await (const audioBuffer of this._audioBuffers) {
          const audioBufferData = this._audioBufferData.get(audioBuffer);

          const previousFFT = audioBufferData.currentFFT;
          audioBufferData.currentFFT = fftBins + "-" + fftInterval;

          if (audioBufferData.fft[audioBufferData.currentFFT]) {
            await this._drawCanvas(
              "full",
              audioBufferData.fft[audioBufferData.currentFFT],
              audioBufferData.color,
              audioBufferData.offset
            );
          } else {
            const offlineAudioCtx = new OfflineAudioContext(audioBuffer);

            const source = offlineAudioCtx.createBufferSource(audioBuffer);
            source.buffer = audioBuffer;

            const analyzer = offlineAudioCtx.createAnalyser();
            analyzer.smoothingTimeConstant = 0;
            analyzer.fftSize = fftBins;

            const processor = offlineAudioCtx.createScriptProcessor(
              fftInterval,
              audioBuffer.numberOfChannels,
              audioBuffer.numberOfChannels
            );

            let fft = [],
              fftChunk = [],
              processCount = 0,
              drawInterval = 64;

            processor.onaudioprocess = () => {
              const bins = new Uint8Array(analyzer.frequencyBinCount);
              analyzer.getByteFrequencyData(bins);
              fft.push(bins);
              fftChunk.push(bins);

              if (processCount++ % drawInterval === 0) {
                // don't await to process async
                this._drawCanvas(
                  "partial",
                  fftChunk,
                  audioBufferData.color,
                  audioBufferData.offset
                );
                fftChunk = [];
              }
            };

            source.connect(analyzer);
            analyzer.connect(processor);
            processor.connect(offlineAudioCtx.destination);
            source.start(0);

            await offlineAudioCtx.startRendering().then(() => {
              // draw any remaining data, wait to complete
              this._drawCanvas(
                "last-partial",
                fftChunk,
                audioBufferData.color,
                audioBufferData.offset
              );

              audioBufferData.fft[audioBufferData.currentFFT] = fft;
            });
          }
        }
      }
    }
  </script>
  <script>
    const baseAudioSelect = document.getElementById("base-audio-select");
    const comparisonAudioSelect = document.getElementById(
      "comparison-audio-select"
    );
    const multipleAudioSelect = document.getElementById(
      "multiple-audio-select"
    );

    const baseAudioFile = document.getElementById("base-audio-file");
    const comparisonAudioFile = document.getElementById(
      "comparison-audio-file"
    );
    const multipleAudioFile = document.getElementById("multiple-audio-file");

    setSelectOptions(baseAudioSelect);
    setSelectOptions(comparisonAudioSelect);
    setSelectOptions(multipleAudioSelect);

    handleFileOrSelect(baseAudioSelect, baseAudioFile);
    handleFileOrSelect(comparisonAudioSelect, comparisonAudioFile);
    handleFileOrSelect(multipleAudioSelect, multipleAudioFile);

    const setAudioFormData = () => {
      const formData = Object.fromEntries(
        new FormData(document.audioForm).entries()
      );
      audioFormData = {
        audio: {
          base: mapClipInput(baseAudioSelect, baseAudioFile),
          comparison: mapClipInput(comparisonAudioSelect, comparisonAudioFile),
          multiple: mapClipInput(multipleAudioSelect, multipleAudioFile),
        },
        correlationMode: formData.correlationMode,
      };
    };

    const setOptionsFormData = () => {
      optionsFormData = Object.fromEntries(
        new FormData(document.optionsForm).entries()
      );
    };

    document.audioForm.addEventListener("change", setAudioFormData);
    document.audioForm.reset();
    setAudioFormData();

    document.optionsForm.addEventListener("change", setOptionsFormData);
    document.optionsForm.reset();
    setOptionsFormData();

    // mode select
    const twoClipsModeEl = document.getElementById("two-clips-mode");
    const multipleClipsModeEl = document.getElementById("multiple-clips-mode");

    const twoClipsFieldsetEl = document.getElementById("two-clips-fieldset");
    const multipleClipsFieldsetEl = document.getElementById(
      "multiple-clips-fieldset"
    );

    const findCorrelationEl = document.getElementById("find-correlation");

    // correlation options
    const correlationMethodEl = document.getElementById("correlation-method");

    const correlationMethodRowEl = document.getElementById(
      "correlation-method-row"
    );

    const correlationThreadsRowEl = document.getElementById(
      "correlation-threads-row"
    );

    const correlationThresholdRowEl = document.getElementById(
      "correlation-threshold-row"
    );

    // correlation results
    const correlationCoefficientRowEl = document.getElementById(
      "correlation-coefficient-row"
    );
    const correlationSampleOffsetRowEl = document.getElementById(
      "correlation-sample-offset-row"
    );

    const correlationResultsJsonRowEl = document.getElementById(
      "correlation-results-json-row"
    );

    const correlationResultsJsonEl = document.getElementById(
      "correlation-results-json"
    );
    const correlationCoefficientEl = document.getElementById(
      "correlation-coefficient"
    );
    const correlationSampleOffsetEl = document.getElementById(
      "correlation-sample-offset"
    );
    const correlationTimeSpent = document.getElementById(
      "correlation-time-spent"
    );
    const correlationBytesPerSecEl = document.getElementById(
      "correlation-bytes-per-sec"
    );
    const correlationRateEl = document.getElementById("correlation-rate");

    const getFFTContainer = (id, name, title = "") => `
    <fieldset id="${id}-fieldset" title='${title}' class="column">
      <legend>${name ? `${name} ` : ""}Audio</legend>
      <div id="${id}-fft"></div>
    </fieldset>
    `;

    const fftContainer = document.getElementById("fft-container");
    const resultContainer = document.getElementById("result-fft-container");

    const selectedClips = new Map();
    let audioData = {};

    const reset = () => {
      // destroy all FFTs
      Object.entries(audioData).forEach(([clip, fft]) => {
        fft.fft.destroy();
      });

      audioData = {};
      document.audioForm.reset();
      correlationResultsJsonEl.innerHTML = "";
      correlationCoefficientEl.innerHTML = "-";
      correlationSampleOffsetEl.innerHTML = "-";
      correlationTimeSpent.innerHTML = "-";
      correlationBytesPerSecEl.innerHTML = "-";
      correlationRateEl.innerHTML = "-";
    };

    const twoClipsMode = "two-clips-mode";
    const multipleClipsMode = "multiple-clips-mode";

    let mode;

    // thread option control
    document.getElementById("correlation-threads").value =
      navigator.hardwareConcurrency - 1;

    const correlationThreadControl = () => {
      if (
        correlationMethodEl.value === "syncWorkerConcurrent" ||
        mode === multipleClipsMode
      ) {
        correlationThreadsRowEl.style = "";
      } else {
        correlationThreadsRowEl.style = "display: none;";
      }
    };

    correlationMethodEl.addEventListener("change", correlationThreadControl);

    const setTwoClipsMode = () => {
      mode = twoClipsMode;

      // destroy the multiple clip ffts
      multipleClipsFieldsetEl.style = "display: none;";
      correlationResultsJsonRowEl.style = "display: none;";
      correlationThresholdRowEl.style = "display: none;";
      correlationMethodRowEl.style = "";
      correlationThreadControl();
      reset();
      twoClipsModeEl.checked = true;
      multipleClipsModeEl.checked = false;

      // show the two clip ffts
      twoClipsFieldsetEl.style = "";
      correlationCoefficientRowEl.style = "";
      correlationSampleOffsetRowEl.style = "";

      // FFT setup
      fftContainer.innerHTML =
        getFFTContainer(baseAudioClipKey, "Base") +
        getFFTContainer(comparisonAudioClipKey, "Comparison");
      resultContainer.innerHTML = getFFTContainer(
        correlationAudioClipKey,
        "Correlation"
      );

      const baseAudioFFTContainerEl = document.getElementById(
        baseAudioClipKey + "-fft"
      );
      const comparisonAudioFFTContainerEl = document.getElementById(
        comparisonAudioClipKey + "-fft"
      );
      const correlationAudioFFTContainerEl = document.getElementById(
        correlationAudioClipKey + "-fft"
      );

      baseAudioFFTContainerEl.innerHTML = fftPlaceholders[baseAudioClipKey];
      comparisonAudioFFTContainerEl.innerHTML =
        fftPlaceholders[comparisonAudioClipKey];
      correlationAudioFFTContainerEl.innerHTML =
        fftPlaceholders[correlationAudioClipKey];
    };

    const setMultipleClipsMode = () => {
      mode = multipleClipsMode;

      // destroy the two clip ffts
      twoClipsFieldsetEl.style = "display: none;";
      // hide single match results
      correlationCoefficientRowEl.style = "display: none;";
      correlationSampleOffsetRowEl.style = "display: none;";
      correlationThresholdRowEl.style = "";
      correlationMethodRowEl.style = "display: none;";
      correlationThreadControl();
      reset();
      multipleClipsModeEl.checked = true;
      twoClipsModeEl.checked = false;

      // show the multiple clip ffts
      multipleClipsFieldsetEl.style = "";
      correlationResultsJsonRowEl.style = "";

      // FFT setup
      fftContainer.innerHTML = "";
      resultContainer.innerHTML = "";
    };

    const selectAudioFieldControl = (newMode) => {
      if (mode !== newMode) {
        if (newMode === twoClipsMode) {
          setTwoClipsMode();
        } else if (newMode === multipleClipsMode) {
          setMultipleClipsMode();
        }
      }
    };

    setTwoClipsMode();

    const correlationButtonControl = () => {
      if (mode === twoClipsMode) {
        findCorrelationEl.disabled = !(
          audioData[baseAudioClipKey] && audioData[comparisonAudioClipKey]
        );
      } else if (mode === multipleClipsMode) {
        findCorrelationEl.disabled = Object.keys(audioData).length < 2;
      }
    };

    const destroyCorrelationFFT = () => {
      for (const key in audioData) {
        if (key.match(/correlation/)) {
          audioData[key].fft.destroy();
          delete audioData[key];
        }
      }

      if (mode === twoClipsMode) {
        resultContainer.innerHTML = getFFTContainer(
          correlationAudioClipKey,
          "Correlation"
        );
      } else if (mode === multipleClipsMode) {
        resultContainer.innerHTML = "";
      }
    };

    const updateFFTCanvasSize = () => {
      const maxLength = Object.values(audioData)
        .map(({ fft }) => fft.length)
        .reduce((acc, len) => (acc > len ? acc : len), 0);

      Object.values(audioData).forEach(({ fft }) => {
        fft.displayLength = maxLength;
      });
    };

    const fftColors = {
      0: [0, 255, 255],
      1: [255, 255, 0],
      2: [0, 0, 255],
      3: [0, 255, 0],
      base: [0, 255, 255],
      4: [255, 0, 0],
      5: [255, 0, 255],
      comparison: [255, 255, 0],
      6: [255, 255, 255],
    };

    const getAudioFFT = async (key, data) => {
      const files = Object.keys(audioData).length;

      const fft = new FFTCanvas(key);

      await fft.addAudioBuffer(data, {
        color: fftColors[key] || fftColors[files] || [255, 255, 0],
      });

      return fft;
    };

    const getAudioKey = (audio) => {
      if (audio instanceof File) {
        return audio.name;
      } else {
        return audio;
      }
    };

    const downloadAudio = async (audio) => {
      if (audio instanceof File) {
        return audio.arrayBuffer();
      } else {
        return fetch(audio).then((res) => res.arrayBuffer());
      }
    };

    const replaceAudioData = async (audio, audioKey) => {
      const audioName = getAudioKey(audio);
      const previousAudioData = audioData[audioKey];

      if (previousAudioData?.name !== audioName) {
        previousAudioData && previousAudioData.fft.destroy();

        audioData[audioKey] = {
          fft: await getAudioFFT(audioKey, await downloadAudio(audio)),
          name: audioName,
        };
      }
    };

    const updateSelectedAudio = async (audio) => {
      if (mode === twoClipsMode) {
        if (audioData.multipleClips) {
          for (const { fft } of audioData.multipleClips) {
            fft.destroy();
          }
          delete audioData.multipleClips;
        }

        await replaceAudioData(audio.base[0], baseAudioClipKey);
        await replaceAudioData(audio.comparison[0], comparisonAudioClipKey);
      } else if (mode === multipleClipsMode) {
        const newKeys = audio.multiple.map((v) => getAudioKey(v));

        for (const key in audioData) {
          if (!newKeys.includes(key) && key !== correlationAudioClipKey) {
            audioData[key].fft.destroy();
            delete audioData[key];

            document.getElementById(key + "-fieldset").remove();
          }
        }

        for await (const clip of audio.multiple) {
          const key = getAudioKey(clip);

          if (!audioData[key]) {
            const node = document.createElement("div");
            node.innerHTML = getFFTContainer(key, key);

            document.getElementById("fft-container").appendChild(node);
          }

          await replaceAudioData(clip, key);
        }
      }

      updateFFTCanvasSize();
      correlationButtonControl();
      destroyCorrelationFFT();
    };

    document.audioForm.addEventListener("change", () => {
      selectAudioFieldControl(audioFormData.correlationMode);
      updateSelectedAudio(audioFormData.audio);
    });

    const drawFFTs = () => {
      Object.values(audioData).forEach(({ fft }) => fft.drawFFT());
    };

    const fftOptionsEl = document.getElementById("fft-options");
    fftOptionsEl.addEventListener("change", drawFFTs);

    let resizeTimeout;
    window.addEventListener("resize", () => {
      clearTimeout(resizeTimeout);
      resizeTimeout = setTimeout(drawFFTs, 100);
    });

    // set FFT options
    const addOption = (el) => (value) =>
      (el.innerHTML += `<option value="${value}">${value}</option>`);

    const fftBinsEl = document.getElementById("fft-bins");
    const fftIntervalEl = document.getElementById("fft-interval");
    FFTCanvas.FFT_BIN_OPTIONS.forEach(addOption(fftBinsEl));
    FFTCanvas.FFT_INTERVAL_OPTIONS.forEach(addOption(fftIntervalEl));
  </script>
  <script>
    const audioBufferToSynAudioParameter = (audioBuffer) => {
      const synAudioParam = {
        samplesDecoded: audioBuffer.length,
        sampleRate: audioBuffer.sampleRate,
        channelData: [],
      };

      for (let i = 0; i < audioBuffer.numberOfChannels; i++)
        synAudioParam.channelData.push(audioBuffer.getChannelData(i));

      return synAudioParam;
    };

    const findCorrelationMultiple = async () => {
      const params = Object.entries(audioData)
        .filter(([k]) => !k.includes("correlation"))
        .map(([k, v]) => ({
          name: k,
          data: audioBufferToSynAudioParameter(v.fft.audioBuffers[0]),
        }));

      const synAudio = new SynAudio({
        correlationSampleSize: parseInt(
          document.getElementById("correlation-sample-size").value
        ),
        initialGranularity: parseInt(
          document.getElementById("initial-granularity").value
        ),
        correlationThreshold: parseFloat(
          document.getElementById("correlation-threshold")
        ),
      });

      const start = performance.now();
      const results = await synAudio.syncMultiple(
        params,
        parseInt(document.getElementById("correlation-threads").value)
      );
      const duration = (performance.now() - start) / 1000;

      for (const stem of results) {
        for (const matches of stem) {
          audioData[matches.name].fft.translateXSamples(matches.sampleOffset);
        }
      }

      destroyCorrelationFFT();

      let totalLength = 0,
        averageSampleRate = 0,
        averageChannelCount = 0,
        bufferCount = 0;

      for (let i = 0; i < results.length; i++) {
        const stem = results[i];
        const correlationKey = "correlation" + i;

        const node = document.createElement("div");
        node.innerHTML = getFFTContainer(
          correlationKey,
          "Match Group " + (i + 1) + " ",
          JSON.stringify(stem, null, 2)
        );
        resultContainer.appendChild(node);

        audioData[correlationKey] = {};
        audioData[correlationKey].fft = new FFTCanvas(correlationKey);

        for (const match of stem) {
          const fft = audioData[match.name].fft;
          const audioBuffer = fft.audioBuffers[0];
          totalLength += audioBuffer.length;
          averageSampleRate += audioBuffer.sampleRate;
          averageChannelCount += audioBuffer.numberOfChannels;
          bufferCount++;

          audioData[correlationKey].fft.addAudioBuffer(audioBuffer, {
            ...fft.getAudioBufferData(audioBuffer),
            offset: match.sampleOffset,
          });
        }
      }

      averageSampleRate /= bufferCount;
      averageChannelCount /= bufferCount;

      const result = {
        timeSpent: duration,
        rate: totalLength / averageSampleRate / duration,
        sampleRate: averageSampleRate,
        bytesPerSecond: (totalLength * averageChannelCount) / duration,
        matches: results,
      };

      updateFFTCanvasSize();

      correlationResultsJsonEl.innerHTML = `<pre class="popover-content">${JSON.stringify(
        results,
        null,
        2
      )}</pre>`;

      return result;
    };

    const findCorrelation = async (method) => {
      const baseFFT = audioData[baseAudioClipKey].fft;
      const comparisonFFT = audioData[comparisonAudioClipKey].fft;
      const baseAudioBuffer = baseFFT.audioBuffers[0];
      const comparisonAudioBuffer = comparisonFFT.audioBuffers[0];

      const synAudio = new SynAudio({
        correlationSampleSize: parseInt(
          document.getElementById("correlation-sample-size").value
        ),
        initialGranularity: parseInt(
          document.getElementById("initial-granularity").value
        ),
      });

      const start = performance.now();
      const result = await synAudio[method](
        audioBufferToSynAudioParameter(baseAudioBuffer),
        audioBufferToSynAudioParameter(comparisonAudioBuffer),
        parseInt(document.getElementById("correlation-threads").value)
      );
      const duration = (performance.now() - start) / 1000;

      result.timeSpent = duration;
      result.rate =
        baseAudioBuffer.length / baseAudioBuffer.sampleRate / duration;
      result.sampleRate = baseAudioBuffer.sampleRate;
      result.bytesPerSecond =
        (baseAudioBuffer.length * baseAudioBuffer.numberOfChannels) / duration;

      await comparisonFFT.translateXSamples(result.sampleOffset);

      destroyCorrelationFFT();

      audioData[correlationAudioClipKey] = {};
      audioData[correlationAudioClipKey].fft = new FFTCanvas(
        correlationAudioClipKey
      );
      audioData[correlationAudioClipKey].fft.addAudioBuffer(
        baseAudioBuffer,
        baseFFT.getAudioBufferData(baseAudioBuffer)
      );
      audioData[correlationAudioClipKey].fft.addAudioBuffer(
        comparisonAudioBuffer,
        {
          ...comparisonFFT.getAudioBufferData(comparisonAudioBuffer),
          offset: result.sampleOffset,
        }
      );
      updateFFTCanvasSize();

      correlationCoefficientEl.innerHTML = result.correlation.toFixed(4);
      correlationSampleOffsetEl.innerHTML = `${result.sampleOffset} @ ${result.sampleRate} Hz`;

      return result;
    };

    findCorrelationEl.addEventListener("click", async () => {
      findCorrelationEl.disabled = true;

      if (mode === twoClipsMode) {
        const result = await findCorrelation(correlationMethodEl.value);

        correlationCoefficientEl.innerHTML = result.correlation.toFixed(4);
        correlationSampleOffsetEl.innerHTML = `${result.sampleOffset} @ ${result.sampleRate} Hz`;
        correlationTimeSpent.innerHTML =
          result.timeSpent.toFixed(4) + " seconds";
        correlationRateEl.innerHTML = result.rate.toFixed(2) + " X";
        correlationBytesPerSecEl.innerHTML =
          Math.round(result.bytesPerSecond / 1024) + " KiB/s";
      } else {
        const result = await findCorrelationMultiple();

        correlationTimeSpent.innerHTML =
          result.timeSpent.toFixed(4) + " seconds";
        correlationRateEl.innerHTML = result.rate.toFixed(2) + " X";
        correlationBytesPerSecEl.innerHTML =
          Math.round(result.bytesPerSecond / 1024) + " KiB/s";
      }

      findCorrelationEl.disabled = false;
    });
  </script>
</html>
