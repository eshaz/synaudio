<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=1300" />
    <title>SynAudio Demo</title>
    <meta
      name="description"
      content="SynAudio - JavaScript library that finds the synchronization point between two similar audio clips"
    />
    <meta name="theme-color" content="#000000" />
    <meta name="title" content="SynAudio Demo" />
    <script src="synaudio.min.js"></script>
  </head>
  <style>
    html,
    body {
      text-size-adjust: none;
    }
    body {
      background: linear-gradient(
            217deg,
            rgba(255, 0, 0, 0.3),
            rgba(255, 0, 0, 0) 70.71%
          )
          fixed,
        linear-gradient(127deg, rgba(0, 255, 0, 0.3), rgba(0, 255, 0, 0) 70.71%)
          fixed,
        linear-gradient(336deg, rgba(0, 0, 255, 0.3), rgba(0, 0, 255, 0) 70.71%)
          fixed;
      font-family: monospace;
      margin: 0 2%;
    }
    header {
      text-align: center;
    }
    .header-links {
      font-size: 16px;
      font-family: sans-serif;
      text-decoration: none;
      user-select: none;
    }
    .header-link {
      text-decoration: none;
    }
    strong {
      font-family: sans-serif;
    }
    input,
    label,
    button,
    select {
      margin: 5px;
    }
    pre {
      margin: 0px;
    }
    label {
      user-select: none;
    }
    button {
      user-select: none;
    }
    hr {
      margin: 20px 0;
    }
    .column {
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
    }
    .row {
      display: flex;
      flex-direction: row;
    }
    .center {
      align-items: center;
      justify-content: center;
    }
    .grow {
      display: flex;
      flex: 1;
    }
  </style>
  <body>
    <div class="row" style="justify-content: center">
      <fieldset name="base-upload" class="row">
        <legend>Correlation Between Two Clips</legend>
        <ol>
          <li>
            <div id="base-audio-container">
              <select id="base-audio-select">
                <option value="" disabled selected>
                  Select a base audio clip
                </option>
              </select>
              <span>or</span>
              <input
                type="file"
                id="base-file-selector"
                accept=".mp3, .mp2, .mp1, .mpg, .ogg, .opus"
              />
            </div>
          </li>
          <li>
            <div id="comparison-audio-container">
              <select id="comparison-audio-select">
                <option value="" disabled selected>
                  Select a comparison audio clip
                </option>
              </select>
              <span>or</span>
              <input
                type="file"
                id="comparison-file-selector"
                accept=".mp3, .mp2, .mp1, .mpg, .ogg, .opus"
              />
            </div>
          </li>
          <li>
            <button id="find-correlation" disabled>Find Correlation</button>
          </li>
        </ol>
      </fieldset>
      <fieldset id="synaudio-results" class="row" style="flex-grow: 1">
        <legend>SynAudio Results</legend>
        <table style="font-weight: bold; border-spacing: 10px 0; width: 100%">
          <tr>
            <td>Correlation Coefficient</td>
            <td style="color: darkred" id="correlation-coefficient">-</td>
          </tr>
          <tr>
            <td>Sample Offset</td>
            <td style="color: darkred" id="correlation-sample-offset">-</td>
          </tr>
          <tr>
            <td>Time spent</td>
            <td style="color: darkred" id="correlation-time-spent">-</td>
          </tr>
          <tr>
            <td>Rate (1x is realtime)</td>
            <td style="color: darkred" id="correlation-rate">-</td>
          </tr>
          <tr>
            <td>Bytes per second</td>
            <td style="color: darkred" id="correlation-bytes-per-sec">-</td>
          </tr>
        </table>
      </fieldset>
      <fieldset id="synaudio-options" class="column">
        <legend>SynAudio Options</legend>
        <table>
          <tr>
            <td>
              <label for="correlation-method">Correlation Method</label>
            </td>
            <td>
              <select id="correlation-method">
                <option value="sync">sync</option>
                <option value="syncWorker">syncWorker</option>
                <option selected value="syncWorkerConcurrent">
                  syncWorkerConcurrent
                </option>
              </select>
            </td>
          </tr>

          <tr>
            <td>
              <label for="correlation-sample-size"
                >Correlation Sample Size</label
              >
            </td>
            <td>
              <input id="correlation-sample-size" type="number" value="11025" />
            </td>
          </tr>
          <tr>
            <td>
              <label for="initial-granularity">Initial Granularity</label>
            </td>
            <td>
              <input id="initial-granularity" type="number" value="16" />
            </td>
          </tr>
        </table>
      </fieldset>
      <fieldset id="fft-options" class="column">
        <legend>FFT Options</legend>
        <table>
          <tr>
            <td>
              <label for="fft-bins">Bin Size (height)</label>
            </td>
            <td>
              <select name="fft-bins" id="fft-bins">
                <option selected value="auto">auto</option>
              </select>
            </td>
          </tr>
          <tr>
            <td>
              <label for="fft-interval">Interval Size (width)</label>
            </td>
            <td>
              <select name="fft-interval" id="fft-interval">
                <option selected value="auto">auto</option>
              </select>
            </td>
          </tr>
          <tr>
            <td>
              <label for="fft-scale">Scale</label>
            </td>
            <td>
              <select name="fft-scale" id="fft-scale">
                <option selected value="log">logarithmic</option>
                <option value="lin">linear</option>
              </select>
            </td>
          </tr>
        </table>
      </fieldset>
    </div>
    <fieldset class="column">
      <legend>Base Audio FFT</legend>
      <div id="base-fft"></div>
    </fieldset>
    <fieldset class="column">
      <legend>Comparison Audio FFT</legend>
      <div id="comparison-fft"></div>
    </fieldset>
    <fieldset class="column">
      <legend>SynAudio Result FFT</legend>
      <div id="correlation-fft"></div>
    </fieldset>
  </body>
  <script>
    "use strict";
    const audioCtx = new AudioContext();
    audioCtx.onstatechange = () => {
      if (audioCtx !== "running") audioCtx.resume();
    };
    audioCtx.destination.channelCount = audioCtx.destination.maxChannelCount;

    const PROGRESS_FACTOR = 100;

    const PLAY = "▶";
    const STOP = "■";

    class WebAudioPlayer {
      constructor(audioBuffer) {
        this.audioBuffer = audioBuffer;

        this.buildPlayer();

        this.startProgress = () => {
          clearInterval(this.progressInterval);
          this.progressInterval = setInterval(() => {
            if (this.action === STOP) {
              const currentTime =
                this.offset +
                (audioCtx.currentTime * PROGRESS_FACTOR - this.start);
              this._progressBarEl.value = currentTime;
              this._timeEl.innerHTML = this.getTime(
                currentTime / PROGRESS_FACTOR
              );
            }
          }, 2);
        };
        this.stopProgress = () => {
          clearInterval(this.progressInterval);
        };
      }

      buildPlayer() {
        this._playerEl = document.createElement("div");

        this._progressBarEl = document.createElement("input");
        this._progressBarEl.value = 0;
        this._progressBarEl.type = "range";
        this._progressBarEl.style = "width: 100%; margin: 0; padding: 0;";
        this._progressBarEl.oninput = () => this.seek();

        this._playbackEl = document.createElement("button");
        this._playbackEl.style =
          "display: flex; justify-content: center; width: 25px;";
        this._playbackEl.onclick = () => this.playPause();
        this._playbackEl.innerHTML = PLAY;

        this._timeEl = document.createElement("div");
        this._timeEl.style =
          "display: flex; align-items: center; padding-left: 5px;";
        this._timeEl.innerHTML = "00:00.000";

        const playerControlsEl = document.createElement("div");
        playerControlsEl.style =
          "display: flex; flex-direction: row; align-items: center;";

        this._playerEl.appendChild(this._progressBarEl);
        this._playerEl.appendChild(playerControlsEl);
        playerControlsEl.appendChild(this._playbackEl);
        playerControlsEl.appendChild(this._timeEl);
      }

      get action() {
        return this._playbackEl.innerHTML;
      }

      get playerEl() {
        return this._playerEl;
      }

      getTime(seconds) {
        return new Date(seconds * 1000).toISOString().substr(14, 9);
      }

      seek() {
        this.stop();
        this.play(parseFloat(this._progressBarEl.value));
      }

      play(offset = 0) {
        // start playing audio
        audioCtx.resume();
        this.source = audioCtx.createBufferSource();
        this.source.buffer = this.audioBuffer;
        this.source.connect(audioCtx.destination);
        this.source.start(0, offset / PROGRESS_FACTOR);
        this.source.onended = () => {
          this.stop();
        };

        // setup progress bar
        this.start = audioCtx.currentTime * PROGRESS_FACTOR;
        this.offset = offset;
        this._progressBarEl.min = 0;
        this._progressBarEl.max = this.audioBuffer.duration * PROGRESS_FACTOR;
        this._progressBarEl.value = offset;

        // start progress bar and add event listeners
        this._progressBarEl.addEventListener("pointerup", this.startProgress);
        this._progressBarEl.addEventListener("pointerdown", this.stopProgress);
        this.startProgress();

        // update file status and play button
        this._playbackEl.innerHTML = STOP;
      }

      stop() {
        // stop playing audio
        if (this.source) {
          this.source.onended = null;
          this.source.stop();
          this.source.disconnect();
        }

        // stop progress bar and clear event listeners
        this._progressBarEl.removeEventListener(
          "pointerup",
          this.startProgress
        );
        this._progressBarEl.removeEventListener(
          "pointerdown",
          this.stopProgress
        );
        this.stopProgress();

        // update file status and play button
        this._playbackEl.innerHTML = PLAY;
      }

      playPause() {
        if (this.action === PLAY) {
          this.play();
        } else {
          this.stop();
        }
      }
    }

    class FFTCanvas {
      static FFT_BIN_OPTIONS = [
        32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768,
      ];

      static FFT_INTERVAL_OPTIONS = [256, 512, 1024, 2048, 4096, 8192, 16384];

      constructor(canvasContainerId) {
        this._canvasContainerId = canvasContainerId;
        this._translatedSamples = 0;

        this._sampleRate = audioCtx.sampleRate;
        this._audioBuffers = [];
        this._audioBufferData = new WeakMap();

        this._heightDivision = 6;

        this._newCanvasWorker();
      }

      async addAudioBuffer(data, audioBufferData = {}) {
        let decoded = data;

        if (!(data instanceof AudioBuffer))
          decoded = await audioCtx.decodeAudioData(data);

        this._audioBuffers.push(decoded);
        this._audioBufferData.set(decoded, {
          color: audioBufferData.color, // rgb
          offset: audioBufferData.offset || 0,
          fft: audioBufferData.fft || {},
        });

        // need to overlap the audio buffer based on offset
        this._newPlayer(this.concatAudioBuffers());
      }

      concatAudioBuffers() {
        return this._audioBuffers
          .map((buffer) => ({
            buffer,
            ...this._audioBufferData.get(buffer),
          }))
          .sort((a, b) => a.offset - b.offset)
          .reduce((finalBuffer, buffer) => {
            for (let i = 0; i < this.channelCount; i++) {
              finalBuffer.copyToChannel(
                buffer.buffer.getChannelData(i),
                i,
                buffer.offset
              );
            }
            return finalBuffer;
          }, audioCtx.createBuffer(this.channelCount, this.length, this.sampleRate));
      }

      get audioBuffers() {
        return this._audioBuffers;
      }

      getAudioBufferData(audioBuffer) {
        return this._audioBufferData.get(audioBuffer);
      }

      destroy() {
        this._webAudioPlayer.stop();
        this._terminateCanvas();
        this._canvasContainer.innerHTML = "";
      }

      get channelCount() {
        return this.audioBuffers.reduce(
          (acc, audioBuffer) =>
            acc > audioBuffer.numberOfChannels
              ? acc
              : audioBuffer.numberOfChannels,
          0
        );
      }

      get sampleRate() {
        return audioCtx.sampleRate;
      }

      get length() {
        return this.audioBuffers.reduce(
          (acc, audioBuffer) =>
            acc > audioBuffer.length ? acc : audioBuffer.length,
          0
        );
      }

      get displayLength() {
        return this._displayLength;
      }

      set displayLength(length) {
        const oldDisplayLength = this._displayLength;

        this._displayLength = length || this.length;

        if (oldDisplayLength !== this._displayLength) {
          this.drawFFT();
        }
      }

      get height() {
        return this.fftBins / 2;
      }

      get width() {
        return window.innerWidth * 0.94; //document.getElementsByTagName("body")[0].clientWidth;
      }

      get fftInterval() {
        const maxWidth = this.width;
        const fftInterval = document.getElementById("fft-interval").value;

        return fftInterval === "auto"
          ? FFTCanvas.FFT_INTERVAL_OPTIONS.reduceRight((acc, val) =>
              maxWidth > this._displayLength / val ? val : acc
            )
          : parseInt(fftInterval);
      }

      get fftBins() {
        const maxHeight = window.innerHeight / this._heightDivision;
        const fftBins = document.getElementById("fft-bins").value;

        return fftBins === "auto"
          ? FFTCanvas.FFT_BIN_OPTIONS.reduceRight((acc, val) =>
              maxHeight < val ? val : acc
            )
          : parseInt(fftBins);
      }

      get fftScale() {
        return document.getElementById("fft-scale").value;
      }

      _sampleToPixel(sample) {
        const fftInterval = this.fftInterval;
        const widthScale = this.width / (this.displayLength / fftInterval);

        return Math.round((sample / fftInterval) * widthScale) || 0;
      }

      _newPlayer(audioBuffer) {
        if (this._webAudioPlayer) this._webAudioPlayer.stop();

        this._webAudioPlayer = new WebAudioPlayer(audioBuffer);
        this._playerEl = this._webAudioPlayer._playerEl;
      }

      _newCanvasWorker() {
        const source = () => {
          let fftXCursor,
            fftYCursor,
            widthScale,
            displayLength,
            canvas,
            canvasCtx,
            patternCanvas,
            patternCanvasCtx,
            logTables,
            sampleRate,
            fftScale,
            fftInterval,
            fftBins;

          const fill = (fillStyle, x, y, width, height) => {
            canvasCtx.fillStyle = fillStyle;
            canvasCtx.fillRect(x, y, width, height);
          };

          const fillPattern = (x, y, width, height) => {
            fill(
              canvasCtx.createPattern(patternCanvas, "repeat"),
              x,
              y,
              width,
              height
            );
          };

          self.onmessage = async ({ data: { name, payload, messageId } }) => {
            switch (name) {
              case "init":
                // precalculate logarithmic rectangle heights
                logTables = {};
                sampleRate = payload.sampleRate;
                const sampleRateLog = Math.log10(sampleRate / 2);

                for (let binOption of payload.fftBinOptions) {
                  binOption /= 2;

                  logTables[binOption] = [];

                  const logGap =
                    binOption /
                    ((Math.log10(binOption - 1) * (binOption - 1)) /
                      sampleRateLog);

                  for (let i = 0; i < binOption; i++)
                    logTables[binOption].push(
                      Math.round(
                        ((Math.log10(i) * (binOption - 1)) / sampleRateLog) *
                          logGap
                      )
                    );
                }

                patternCanvas = payload.patternCanvas;
                patternCanvasCtx = patternCanvas.getContext("2d", {
                  alpha: false,
                });

                patternCanvas.width = 8;
                patternCanvas.height = 8;
                patternCanvasCtx.fillStyle = "#333";
                patternCanvasCtx.fillRect(
                  0,
                  0,
                  patternCanvas.width,
                  patternCanvas.height
                );
                /*patternCanvasCtx.beginPath();
                patternCanvasCtx.moveTo(0, 0);
                patternCanvasCtx.lineTo(8, 8);
                patternCanvasCtx.moveTo(0, 8);
                patternCanvasCtx.lineTo(8, 0);
                patternCanvasCtx.lineWidth = 1;
                patternCanvasCtx.stroke();*/
                break;
              case "canvas":
                fftXCursor = 0;
                fftYCursor = 0;

                canvas = payload.canvas;
                canvasCtx = canvas.getContext("2d", { alpha: false });
                break;
              case "options":
                fftScale = payload.fftScale;
                fftInterval = payload.fftInterval;
                fftBins = payload.fftBins;
                displayLength = payload.displayLength;

                widthScale = canvas.width / (displayLength / fftInterval);
                break;
              case "fill":
                fill(payload, 0, 0, canvas.width, canvas.height);
                break;
              case "fillPattern":
                fillPattern(0, 0, canvas.width, canvas.height);
                break;
              case "draw":
                if (payload.mode === "full") fftXCursor = 0;

                for (const bins of payload.fft) {
                  fftYCursor = 0;

                  let fftYPrevious;

                  for (let binIdx = 0; binIdx < bins.length; binIdx++) {
                    const r = Math.round(
                      (payload.color[0] * bins[binIdx]) / 255
                    );
                    const g = Math.round(
                      (payload.color[1] * bins[binIdx]) / 255
                    );
                    const b = Math.round(
                      (payload.color[2] * bins[binIdx]) / 255
                    );

                    canvasCtx.fillStyle = `rgb(${r},${g},${b})`;

                    fftYPrevious = fftYCursor;
                    fftYCursor =
                      fftScale === "log"
                        ? logTables[bins.length][binIdx]
                        : binIdx;

                    canvasCtx.fillRect(
                      (payload.offset / fftInterval + fftXCursor) * widthScale,
                      bins.length - fftYCursor,
                      widthScale + widthScale / 2,
                      fftYCursor - fftYPrevious
                    );
                  }

                  fftXCursor++;
                }

                if (payload.mode === "last-partial") fftXCursor = 0;
                break;
              case "translateXSamples":
                const image = canvasCtx.getImageData(
                  0,
                  0,
                  canvas.width,
                  canvas.height
                );

                fillPattern(0, 0, canvas.width, canvas.height);
                canvasCtx.putImageData(
                  image,
                  (payload / fftInterval) * widthScale,
                  0
                );
                break;
            }

            self.postMessage(messageId);
          };
        };

        if (this._canvasWorker) {
          this._terminateCanvas();
        }

        this._canvasWorker = new Worker(
          URL.createObjectURL(
            new Blob([`"use strict";(${source.toString()})()`], {
              type: "text/javascript",
            })
          )
        );

        this._messageId = Number.MIN_SAFE_INTEGER;
        this._pendingMessages = new Map();

        this._canvasWorker.onmessage = ({ data: messageId }) => {
          const messagePromise = this._pendingMessages.get(messageId);

          if (messagePromise) {
            messagePromise();
            this._pendingMessages.delete(messageId);
          }
        };

        const offscreenPatternCanvas = document
          .createElement("canvas")
          .transferControlToOffscreen();

        this._postToWorker(
          "init",
          {
            sampleRate: this._sampleRate,
            fftBinOptions: FFTCanvas.FFT_BIN_OPTIONS,
            patternCanvas: offscreenPatternCanvas,
          },
          [offscreenPatternCanvas]
        );
      }

      async _postToWorker(name, payload, transferList) {
        const messageId = this._messageId++;

        return new Promise((resolve, reject) => {
          this._pendingMessages.set(messageId, resolve);
          this._canvasWorker.postMessage(
            { name, payload, messageId },
            transferList
          );
        });
      }

      async _newCanvas() {
        this._canvas = document.createElement("canvas");
        this._canvas.id = this._canvasContainerId + "-canvas";
        this._canvas.width = this.width;
        this._canvas.height = this.height;
        const offscreenCanvas = this._canvas.transferControlToOffscreen();

        this._canvasContainer = document.getElementById(
          this._canvasContainerId
        );

        this._playerEl.style.width = this._sampleToPixel(this.length) + "px";

        this._playerEl.style.marginLeft =
          this._sampleToPixel(this._translatedSamples) + "px";

        this._canvasContainer.innerHTML = "";
        this._canvasContainer.appendChild(this._canvas);
        this._canvasContainer.appendChild(this._playerEl);

        await this._postToWorker("canvas", { canvas: offscreenCanvas }, [
          offscreenCanvas,
        ]);
      }

      async _fillCanvas(fillStyle) {
        await this._postToWorker("fill", fillStyle);
      }

      async _fillPatternCanvas(fillStyle) {
        await this._postToWorker("fillPattern");
      }

      async _drawCanvas(mode, fft, color, offset) {
        await this._postToWorker("draw", { mode, fft, color, offset });
      }

      async _terminateCanvas() {
        // clear out the canvas
        await this._fillCanvas("rgb(255, 255, 255)");
        this._canvasWorker.terminate();
        this._canvasWorker = null;
      }

      async translateXSamples(samples) {
        this._translatedSamples = samples;
        this._playerEl.style.marginLeft =
          this._sampleToPixel(this._translatedSamples) + "px";

        const audioData = this._audioBufferData.get(this._audioBuffers[0]);

        await this._postToWorker(
          "translateXSamples",
          this._translatedSamples - audioData.offset
        );

        audioData.offset = this._translatedSamples;
      }

      async drawFFT() {
        const fftBins = this.fftBins;
        const fftInterval = this.fftInterval;

        if (
          this._canvas?.width !== this.width ||
          this._canvas?.height !== this.height
        )
          await this._newCanvas();

        await this._postToWorker("options", {
          displayLength: this.displayLength,
          fftScale: this.fftScale,
          fftInterval,
          fftBins,
        });

        await this._fillPatternCanvas();

        for await (const audioBuffer of this._audioBuffers) {
          const audioBufferData = this._audioBufferData.get(audioBuffer);

          const previousFFT = audioBufferData.currentFFT;
          audioBufferData.currentFFT = fftBins + "-" + fftInterval;

          if (audioBufferData.fft[audioBufferData.currentFFT]) {
            await this._drawCanvas(
              "full",
              audioBufferData.fft[audioBufferData.currentFFT],
              audioBufferData.color,
              audioBufferData.offset
            );
          } else {
            const offlineAudioCtx = new OfflineAudioContext(audioBuffer);

            const source = offlineAudioCtx.createBufferSource(audioBuffer);
            source.buffer = audioBuffer;

            const analyzer = offlineAudioCtx.createAnalyser();
            analyzer.smoothingTimeConstant = 0;
            analyzer.fftSize = fftBins;

            const processor = offlineAudioCtx.createScriptProcessor(
              fftInterval,
              audioBuffer.numberOfChannels,
              audioBuffer.numberOfChannels
            );

            let fft = [],
              fftChunk = [],
              processCount = 0,
              drawInterval = 64;

            processor.onaudioprocess = () => {
              const bins = new Uint8Array(analyzer.frequencyBinCount);
              analyzer.getByteFrequencyData(bins);
              fft.push(bins);
              fftChunk.push(bins);

              if (processCount++ % drawInterval === 0) {
                // don't await to process async
                this._drawCanvas(
                  "partial",
                  fftChunk,
                  audioBufferData.color,
                  audioBufferData.offset
                );
                fftChunk = [];
              }
            };

            source.connect(analyzer);
            analyzer.connect(processor);
            processor.connect(offlineAudioCtx.destination);
            source.start(0);

            await offlineAudioCtx.startRendering().then(() => {
              // draw any remaining data, wait to complete
              this._drawCanvas(
                "last-partial",
                fftChunk,
                audioBufferData.color,
                audioBufferData.offset
              );

              audioBufferData.fft[audioBufferData.currentFFT] = fft;
            });
          }
        }
      }
    }
  </script>
  <script>
    const baseSelectEl = document.getElementById("base-audio-select");
    const comparisonSelectEl = document.getElementById(
      "comparison-audio-select"
    );

    // prettier-ignore
    const audioClips = {
      ["Flight of the Bumblebee"]: {
        ["Full Audio (MP3 128kb/s)"]: "clips/bumblebee/mpeg.cbr.mp3",
        ["Clip @ 1601425 Samples (MP3 128kb/s)"]: "clips/bumblebee/mpeg.cbr.1601425.mp3",
        ["Clip @ 287549 Samples (MP3 128kb/s)"]: "clips/bumblebee/mpeg.cbr.287549.mp3",
        ["Clip @ 2450800 Samples (MP3 128kb/s)"]: "clips/bumblebee/mpeg.cbr.2450800.mp3",
        ["Clip @ 194648 Samples (MP3 128kb/s)"]: "clips/bumblebee/mpeg.cbr.194648.mp3",
        ["Clip @ 194648 Samples (MP3 64kb/s)"]: "clips/bumblebee/mpeg.64.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s)"]: "clips/bumblebee/mpeg.32.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen2)"]: "clips/bumblebee/mpeg.32.gen2.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen3)"]: "clips/bumblebee/mpeg.32.gen3.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen4)"]: "clips/bumblebee/mpeg.32.gen4.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen5)"]: "clips/bumblebee/mpeg.32.gen5.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen6)"]: "clips/bumblebee/mpeg.32.gen6.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen7)"]: "clips/bumblebee/mpeg.32.gen7.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen8)"]: "clips/bumblebee/mpeg.32.gen8.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen9)"]: "clips/bumblebee/mpeg.32.gen9.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen10)"]: "clips/bumblebee/mpeg.32.gen10.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen11)"]: "clips/bumblebee/mpeg.32.gen11.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen12)"]: "clips/bumblebee/mpeg.32.gen12.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen13)"]: "clips/bumblebee/mpeg.32.gen13.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen14)"]: "clips/bumblebee/mpeg.32.gen14.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen15)"]: "clips/bumblebee/mpeg.32.gen15.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen16)"]: "clips/bumblebee/mpeg.32.gen16.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen17)"]: "clips/bumblebee/mpeg.32.gen17.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen18)"]: "clips/bumblebee/mpeg.32.gen18.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen19)"]: "clips/bumblebee/mpeg.32.gen19.194648.mp3",
        ["Clip @ 194648 Samples (MP3 32kb/s gen20)"]: "clips/bumblebee/mpeg.32.gen20.194648.mp3",
      }
    }

    const setAudioClips = (el) => {
      let html = "";
      for (const [optgroup, options] of Object.entries(audioClips)) {
        html += `<optgroup label="${optgroup}">`;

        for (const [name, value] of Object.entries(options))
          html += `<option value="${value}">${name}</option>`;

        html += "</optgroup>";
      }
      el.innerHTML += html;
    };

    setAudioClips(baseSelectEl);
    setAudioClips(comparisonSelectEl);

    const baseFileInputEl = document.getElementById("base-file-selector");
    const comparisonFileInputEl = document.getElementById(
      "comparison-file-selector"
    );
    const findCorrelationEl = document.getElementById("find-correlation");
    // correlation options
    const correlationMethodEl = document.getElementById("correlation-method");
    const correlationCoefficientEl = document.getElementById(
      "correlation-coefficient"
    );
    const correlationSampleOffsetEl = document.getElementById(
      "correlation-sample-offset"
    );
    const correlationTimeSpent = document.getElementById(
      "correlation-time-spent"
    );
    const correlationBytesPerSecEl = document.getElementById(
      "correlation-bytes-per-sec"
    );
    const correlationRateEl = document.getElementById("correlation-rate");

    const baseAudioClipKey = "base";
    const comparisonAudioClipKey = "comparison";
    const correlationAudioClipKey = "correlation";
    const audioData = {};

    const correlationButtonControl = () => {
      findCorrelationEl.disabled = !(
        audioData[baseAudioClipKey] && audioData[comparisonAudioClipKey]
      );
    };

    const destroyCorrelationFFT = () => {
      if (audioData[correlationAudioClipKey])
        audioData[correlationAudioClipKey].fft.destroy();

      delete audioData[correlationAudioClipKey];
    };

    const fftColors = {
      base: [0, 255, 255],
      comparison: [255, 255, 0],
    };

    const updateFFTCanvasSize = () => {
      const maxLength = Object.values(audioData)
        .map(({ fft }) => fft.length)
        .reduce((acc, len) => (acc > len ? acc : len), 0);

      Object.values(audioData).forEach(({ fft }) => {
        fft.displayLength = maxLength;
      });
    };

    const setAudioClip = async (file, clipType) => {
      if (audioData[clipType]) audioData[clipType].fft.destroy();

      const newAudioData = {};

      audioData[clipType] = newAudioData;
      newAudioData.fft = new FFTCanvas(`${clipType}-fft`);
      newAudioData.data = file;

      await newAudioData.fft.addAudioBuffer(file, {
        color: fftColors[clipType],
      });

      updateFFTCanvasSize();
      destroyCorrelationFFT();
      correlationButtonControl();
    };

    const setAudioSelectionElements = (audioClipKey, selectEl, fileInputEl) => {
      selectEl.addEventListener("change", async (e) => {
        if (e.target.value) {
          const data = await fetch(e.target.value).then((res) =>
            res.arrayBuffer()
          );
          setAudioClip(data, audioClipKey);

          fileInputEl.value = "";
        } else if (!fileInputEl.value) {
          delete audioClips[audioClipKey];
        }
      });

      fileInputEl.addEventListener("change", async (e) => {
        if (e.target.files.length) {
          setAudioClip(await e.target.files[0].arrayBuffer(), audioClipKey);

          selectEl.selectedIndex = 0;
        } else if (fileInputEl.selectedIndex < 1) {
          delete audioClips[audioClipKey];
        }
      });
    };

    setAudioSelectionElements(baseAudioClipKey, baseSelectEl, baseFileInputEl);
    setAudioSelectionElements(
      comparisonAudioClipKey,
      comparisonSelectEl,
      comparisonFileInputEl
    );

    const drawFFTs = () => {
      Object.values(audioData).forEach(({ fft }) => fft.drawFFT());
    };

    const fftOptionsEl = document.getElementById("fft-options");
    fftOptionsEl.addEventListener("change", drawFFTs);

    let resizeTimeout;
    window.addEventListener("resize", () => {
      clearTimeout(resizeTimeout);
      resizeTimeout = setTimeout(drawFFTs, 100);
    });

    // set FFT options
    const addOption = (el) => (value) =>
      (el.innerHTML += `<option value="${value}">${value}</option>`);

    const fftBinsEl = document.getElementById("fft-bins");
    const fftIntervalEl = document.getElementById("fft-interval");
    FFTCanvas.FFT_BIN_OPTIONS.forEach(addOption(fftBinsEl));
    FFTCanvas.FFT_INTERVAL_OPTIONS.forEach(addOption(fftIntervalEl));
  </script>
  <script>
    const audioBufferToSynAudioParameter = (audioBuffer) => {
      const synAudioParam = {
        samplesDecoded: audioBuffer.length,
        sampleRate: audioBuffer.sampleRate,
        channelData: [],
      };

      for (let i = 0; i < audioBuffer.numberOfChannels; i++)
        synAudioParam.channelData.push(audioBuffer.getChannelData(i));

      return synAudioParam;
    };

    const findCorrelation = async (method) => {
      const baseFFT = audioData[baseAudioClipKey].fft;
      const comparisonFFT = audioData[comparisonAudioClipKey].fft;
      const baseAudioBuffer = baseFFT.audioBuffers[0];
      const comparisonAudioBuffer = comparisonFFT.audioBuffers[0];

      const synAudio = new SynAudio({
        correlationSampleSize: parseInt(
          document.getElementById("correlation-sample-size").value
        ),
        initialGranularity: parseInt(
          document.getElementById("initial-granularity").value
        ),
      });

      const start = performance.now();
      const result = await synAudio[method](
        audioBufferToSynAudioParameter(baseAudioBuffer),
        audioBufferToSynAudioParameter(comparisonAudioBuffer),
        navigator.hardwareConcurrency - 1
      );
      const duration = (performance.now() - start) / 1000;

      result.timeSpent = duration;
      result.rate =
        baseAudioBuffer.length / baseAudioBuffer.sampleRate / duration;
      result.sampleRate = baseAudioBuffer.sampleRate;
      result.bytesPerSecond =
        (baseAudioBuffer.length * baseAudioBuffer.numberOfChannels) / duration;

      await comparisonFFT.translateXSamples(result.sampleOffset);

      destroyCorrelationFFT();

      audioData[correlationAudioClipKey] = {};
      audioData[correlationAudioClipKey].fft = new FFTCanvas("correlation-fft");
      audioData[correlationAudioClipKey].fft.addAudioBuffer(
        baseAudioBuffer,
        baseFFT.getAudioBufferData(baseAudioBuffer)
      );
      audioData[correlationAudioClipKey].fft.addAudioBuffer(
        comparisonAudioBuffer,
        {
          ...comparisonFFT.getAudioBufferData(comparisonAudioBuffer),
          offset: result.sampleOffset,
        }
      );
      updateFFTCanvasSize();
      await comparisonFFT.drawFFT();

      return result;
    };

    findCorrelationEl.addEventListener("click", async () => {
      findCorrelationEl.disabled = true;
      const result = await findCorrelation(correlationMethodEl.value);
      findCorrelationEl.disabled = false;

      correlationCoefficientEl.innerHTML = result.correlation.toFixed(4);
      correlationSampleOffsetEl.innerHTML = `${result.sampleOffset} @ ${result.sampleRate} Hz`;
      correlationTimeSpent.innerHTML = result.timeSpent.toFixed(4) + " seconds";
      correlationRateEl.innerHTML = result.rate.toFixed(2) + " X";
      correlationBytesPerSecEl.innerHTML =
        Math.round(result.bytesPerSecond / 1024) + " KiB/s";
    });
  </script>
</html>
